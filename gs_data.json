{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "7qo_cTcAAAAJ&hl=en&oi=ao", "source": "AUTHOR_PROFILE_PAGE", "name": "Licai Sun", "affiliation": "University of Oulu", "organization": 10568258639230347370, "interests": ["Affective computing", "Deep learning", "Machine learning"], "email_domain": "@oulu.fi", "homepage": "https://sunlicai.github.io/", "citedby": 524, "publications": {"7qo_cTcAAAAJ:u-x6o8ySG0sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multi-modal continuous dimensional emotion recognition using recurrent neural network and self-attention mechanism", "pub_year": "2020"}, "filled": false, "author_pub_id": "7qo_cTcAAAAJ:u-x6o8ySG0sC", "num_citations": 75, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1374421166072030237", "cites_id": ["1374421166072030237"]}, "7qo_cTcAAAAJ:9yKSN-GCB0IC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multimodal cross-and self-attention network for speech emotion recognition", "pub_year": "2021"}, "filled": false, "author_pub_id": "7qo_cTcAAAAJ:9yKSN-GCB0IC", "num_citations": 73, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7108440566505772310", "cites_id": ["7108440566505772310"]}, "7qo_cTcAAAAJ:ufrVoPGSRksC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Efficient multimodal transformer with dual-level feature restoration for robust multimodal sentiment analysis", "pub_year": "2023"}, "filled": false, "author_pub_id": "7qo_cTcAAAAJ:ufrVoPGSRksC", "num_citations": 62, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11797713213470971150", "cites_id": ["11797713213470971150"]}, "7qo_cTcAAAAJ:Y0pCki6q_DkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "GCNet: Graph completion network for incomplete multimodal learning in conversation", "pub_year": "2023"}, "filled": false, "author_pub_id": "7qo_cTcAAAAJ:Y0pCki6q_DkC", "num_citations": 60, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4780102554214597486", "cites_id": ["4780102554214597486"]}, "7qo_cTcAAAAJ:8k81kl-MbHgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Mer 2023: Multi-label learning, modality robustness, and semi-supervised learning", "pub_year": "2023"}, "filled": false, "author_pub_id": "7qo_cTcAAAAJ:8k81kl-MbHgC", "num_citations": 41, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15123430258013632077", "cites_id": ["15123430258013632077"]}, "7qo_cTcAAAAJ:qjMakFHDy7sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multimodal emotion recognition and sentiment analysis via attention enhanced recurrent model", "pub_year": "2021"}, "filled": false, "author_pub_id": "7qo_cTcAAAAJ:qjMakFHDy7sC", "num_citations": 29, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2074864759272175627", "cites_id": ["2074864759272175627"]}, "7qo_cTcAAAAJ:kNdYIx-mwKoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MAE-DFER: Efficient Masked Autoencoder for Self-supervised Dynamic Facial Expression Recognition", "pub_year": "2023"}, "filled": false, "author_pub_id": "7qo_cTcAAAAJ:kNdYIx-mwKoC", "num_citations": 28, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12975063113032869666", "cites_id": ["12975063113032869666"]}, "7qo_cTcAAAAJ:3fE2CSJIrl8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Explainable multimodal emotion reasoning", "pub_year": "2023"}, "filled": false, "author_pub_id": "7qo_cTcAAAAJ:3fE2CSJIrl8C", "num_citations": 22, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10556240866665594591", "cites_id": ["10556240866665594591"]}, "7qo_cTcAAAAJ:mVmsd5A6BfQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Gpt-4v with emotion: A zero-shot benchmark for generalized emotion recognition", "pub_year": "2024"}, "filled": false, "author_pub_id": "7qo_cTcAAAAJ:mVmsd5A6BfQC", "num_citations": 21, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5174832529176566147,14468534321187227081", "cites_id": ["5174832529176566147", "14468534321187227081"]}, "7qo_cTcAAAAJ:_FxGoFyzp5QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multimodal temporal attention in sentiment analysis", "pub_year": "2022"}, "filled": false, "author_pub_id": "7qo_cTcAAAAJ:_FxGoFyzp5QC", "num_citations": 20, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1264520225896302830", "cites_id": ["1264520225896302830"]}, "7qo_cTcAAAAJ:UeHWp8X0CEIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multimodal sentiment analysis based on recurrent neural network and multimodal attention", "pub_year": "2021"}, "filled": false, "author_pub_id": "7qo_cTcAAAAJ:UeHWp8X0CEIC", "num_citations": 20, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10135162589677064558", "cites_id": ["10135162589677064558"]}, "7qo_cTcAAAAJ:LkGwnXOMwfcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Emotional reaction analysis based on multi-label graph convolutional networks and dynamic facial expression recognition transformer", "pub_year": "2022"}, "filled": false, "author_pub_id": "7qo_cTcAAAAJ:LkGwnXOMwfcC", "num_citations": 15, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1748934235821809256", "cites_id": ["1748934235821809256"]}, "7qo_cTcAAAAJ:aqlVkmm33-oC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Merbench: A unified evaluation benchmark for multimodal emotion recognition", "pub_year": "2024"}, "filled": false, "author_pub_id": "7qo_cTcAAAAJ:aqlVkmm33-oC", "num_citations": 11, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7174484612291660572", "cites_id": ["7174484612291660572"]}, "7qo_cTcAAAAJ:dhFuZR0502QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MER 2024: Semi-Supervised Learning, Noise Robustness, and Open-Vocabulary Multimodal Emotion Recognition", "pub_year": "2024"}, "filled": false, "author_pub_id": "7qo_cTcAAAAJ:dhFuZR0502QC", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15189426103930935797", "cites_id": ["15189426103930935797"]}, "7qo_cTcAAAAJ:4DMP91E08xMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "HiCMAE: Hierarchical Contrastive Masked Autoencoder for Self-Supervised Audio-Visual Emotion Recognition", "pub_year": "2024"}, "filled": false, "author_pub_id": "7qo_cTcAAAAJ:4DMP91E08xMC", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11019318447597656523", "cites_id": ["11019318447597656523"]}, "7qo_cTcAAAAJ:9ZlFYXVOiuMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "EmotionNAS: Two-stream neural architecture search for speech emotion recognition", "pub_year": "2022"}, "filled": false, "author_pub_id": "7qo_cTcAAAAJ:9ZlFYXVOiuMC", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2380491500013611893", "cites_id": ["2380491500013611893"]}, "7qo_cTcAAAAJ:qxL8FJ1GzNcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SVFAP: Self-supervised video facial affect perceiver", "pub_year": "2024"}, "filled": false, "author_pub_id": "7qo_cTcAAAAJ:qxL8FJ1GzNcC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2170829056293420408", "cites_id": ["2170829056293420408"]}, "7qo_cTcAAAAJ:7PzlFSSx8tAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "AffectGPT: Dataset and Framework for Explainable Multimodal Emotion Recognition", "pub_year": "2024"}, "filled": false, "author_pub_id": "7qo_cTcAAAAJ:7PzlFSSx8tAC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6374429304315607405", "cites_id": ["6374429304315607405"]}, "7qo_cTcAAAAJ:YOwf2qJgpHMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Integrating VideoMAE based model and Optical Flow for Micro-and Macro-expression Spotting", "pub_year": "2023"}, "filled": false, "author_pub_id": "7qo_cTcAAAAJ:YOwf2qJgpHMC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13289047729289202391", "cites_id": ["13289047729289202391"]}, "7qo_cTcAAAAJ:roLk4NBRz8UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Arnet: Automatic refinement network for noisy partial label learning", "pub_year": "2022"}, "filled": false, "author_pub_id": "7qo_cTcAAAAJ:roLk4NBRz8UC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7538199788694897345,9712551109137667992", "cites_id": ["7538199788694897345", "9712551109137667992"]}, "7qo_cTcAAAAJ:QIV2ME_5wuYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multimodal Fusion with Pre-Trained Model Features in Affective Behaviour Analysis In-the-wild", "pub_year": "2024"}, "filled": false, "author_pub_id": "7qo_cTcAAAAJ:QIV2ME_5wuYC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9327797237327040440", "cites_id": ["9327797237327040440"]}, "7qo_cTcAAAAJ:Tyk-4Ss8FVUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multi-modal lie detection method and apparatus, and device", "pub_year": "2022"}, "filled": false, "author_pub_id": "7qo_cTcAAAAJ:Tyk-4Ss8FVUC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7624156814719214953", "cites_id": ["7624156814719214953"]}, "7qo_cTcAAAAJ:eQOLeE2rZwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multimodal dimensional emotion recognition method", "pub_year": "2022"}, "filled": false, "author_pub_id": "7qo_cTcAAAAJ:eQOLeE2rZwMC", "num_citations": 0}, "7qo_cTcAAAAJ:zYLM7Y9cAGgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Automatic lie detection method and apparatus for interactive scenarios, device and medium", "pub_year": "2022"}, "filled": false, "author_pub_id": "7qo_cTcAAAAJ:zYLM7Y9cAGgC", "num_citations": 0}, "7qo_cTcAAAAJ:IjCSPb-OGe4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Physiological signal prediction method", "pub_year": "2022"}, "filled": false, "author_pub_id": "7qo_cTcAAAAJ:IjCSPb-OGe4C", "num_citations": 0}}, "citedby5y": 524, "hindex": 12, "hindex5y": 12, "i10index": 13, "i10index5y": 13, "cites_per_year": {"2021": 22, "2022": 51, "2023": 156, "2024": 294}, "updated": "2024-10-09 08:17:13.997519"}